{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0735efc0",
   "metadata": {},
   "source": [
    "### Minhash con PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6620757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "# Carga ufnciones extra\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('minhash').getOrCreate()\n",
    "\n",
    "# Minhash y texto\n",
    "from pyspark.ml.feature import MinHashLSH\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.sql.functions import col, size\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Graficar\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7049f64b",
   "metadata": {},
   "source": [
    "Podemos definir vectores dispersos en PySpark usando estos parametros de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0e30a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = Vectors.sparse(10, [0, 5, 8], [1, 3, 2])\n",
    "vector.toArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d535757c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Podemos crear un DataFrame con vectores dispersos de la siguiente manera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd70b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_dispersa = [(Vectors.sparse(6, [0, 1, 2], [1.0, 1.0, 1.0]),),\n",
    "                   (Vectors.sparse(6, [2, 3, 4], [1.0, 1.0, 1.0]),),\n",
    "                   (Vectors.sparse(6, [0, 2, 4], [1.0, 1.0, 1.0]),)]\n",
    "\n",
    "matriz_dispersa = spark.createDataFrame(matriz_dispersa)\n",
    "\n",
    "matriz_dispersa.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba38c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentos = spark.createDataFrame([(0, 'a,b,b,c'.split(',')),\n",
    "                                    (1, 'b,c,d'.split(',')),\n",
    "                                    (2, 'a,c'.split(','))],\n",
    "                                   ['id', 'palabras'])\n",
    "\n",
    "documentos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d56736",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol  = 'palabras', \n",
    "                     outputCol = 'features', \n",
    "                     vocabSize = 6, \n",
    "                     minDF     = 1)\n",
    "\n",
    "modelo = cv.fit(documentos)\n",
    "mat_rep = modelo.transform(documentos)\n",
    "\n",
    "mat_rep.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b011d573",
   "metadata": {},
   "source": [
    "#### Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b6d26b",
   "metadata": {},
   "source": [
    "Los datos que usaremos son de la serie Rick y Morty. Corresponde a transcripciones de los dialogos de los personajes. La base de datos cuenta con los siguientes campos:\n",
    "\n",
    "    Indice (Identificadore unico del renglon en la base de datos)\n",
    "    Temporada\n",
    "    Numero de episodio\n",
    "    Nombre del episodio\n",
    "    Linea de dialogo\n",
    "\n",
    "Carguemos los datos en un DataFrame de PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b425a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rym = spark.read.csv('content/RickAndMortyScripts.csv', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9388dced",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rym.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f368917",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rym.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3eb6e4",
   "metadata": {},
   "source": [
    "Para fines del analisis que llevaremos a cabo en este notebook solo haremos uso del as columnas del nombre y el dialogo del personaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d1ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rym = df_rym.select('index', 'name', 'line')\n",
    "df_rym.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4886f4",
   "metadata": {},
   "source": [
    "Para hacer aun mas simple el analisis quedemonos solo con los dialogos de los personajes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908825c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "personajes_principales = ['Rick', 'Morty', 'Beth', 'Jerry', 'Summer']\n",
    "df_rym = df_rym.where(df_rym.name.isin(personajes_principales))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce80742",
   "metadata": {},
   "source": [
    "Revisemos la distribucion de dialogos de los personajes que tienen mas dialogos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc90968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dist_dialog = df_rym.groupBy('name') \\\n",
    "                       .count() \\\n",
    "                       .toPandas()\n",
    "\n",
    "sns.barplot( x = 'name', \n",
    "             y = 'count', \n",
    "             data = df_dist_dialog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8632ea75",
   "metadata": {},
   "source": [
    "#### Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6441b4",
   "metadata": {},
   "source": [
    "##### Limpieza del texto\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53e92f6",
   "metadata": {},
   "source": [
    "Aqui realizaremos el proceso que ya hemos hecho anteriormente, el cual consiste en:\n",
    "\n",
    "    Transformar todo el texto a minusculas\n",
    "    Eliminar signos de puntuacion\n",
    "    Eliminar las palabras vacias, que son palabras que aportan poco contexto al problema\n",
    "\n",
    "Veamos como se encuentra el texto originalmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c78c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rym.limit(3) \\\n",
    "      .toPandas() \\\n",
    "      .loc[0:3, 'line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9a63d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos minusculas\n",
    "df_rym = df_rym.rdd \\\n",
    "               .map(lambda x: (x[0], x[1], x[2].lower())) \\\n",
    "               .toDF(['id', 'nombre', 'dialog']) \n",
    "\n",
    "# Vemos como va el proceso\n",
    "df_rym.limit(3) \\\n",
    "      .toPandas() \\\n",
    "      .loc[0:3,'dialog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb58a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina signos de puntacion\n",
    "df_rym = df_rym.rdd \\\n",
    "           .map(lambda x: (x[0], x[1], x[2].translate(str.maketrans('', '', string.punctuation)))) \\\n",
    "           .toDF(['id', 'nombre', 'dialog']) \n",
    "\n",
    "# Vemos como va el proceso\n",
    "df_rym.limit(3) \\\n",
    "      .toPandas() \\\n",
    "      .loc[0:3,'dialog']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a594bb70",
   "metadata": {},
   "source": [
    "Quitar stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63df7ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos funcion para quitar stop words\n",
    "palabras_vacias = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def quita_palabras_vacias(texto):\n",
    "  texto_limpio = [ palabra for palabra in texto if palabra not in palabras_vacias ]\n",
    "  return texto_limpio\n",
    "\n",
    "# Quitamos stop words\n",
    "df_rym = df_rym.rdd \\\n",
    "           .map(lambda x: (x[0], x[1], x[2].split(' '))) \\\n",
    "           .map(lambda x: (x[0], x[1], quita_palabras_vacias(x[2]))) \\\n",
    "           .toDF(['id', 'nombre', 'dialog']) \\\n",
    "           .filter(size('dialog') > 0) # Elimina texto vacio\n",
    "\n",
    "# Vemos como va el proceso\n",
    "df_rym.limit(7) \\\n",
    "      .toPandas() \\\n",
    "      .loc[0:7,'dialog']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c11104",
   "metadata": {},
   "source": [
    "#### Matriz de representacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f209e14a",
   "metadata": {},
   "source": [
    "Ahora necesitamos representar los datos como una matriz de representacion, la cual nos dice que elementos del vocabulario aparecen en cada elemento del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12666dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol  = 'dialog', \n",
    "                     outputCol = 'features',\n",
    "                     binary    = True, # Solo llena con 0 o 1\n",
    "                     vocabSize = 3000,  # Tamano maximo del vocabulario \n",
    "                     minDF     = 1)    # En cuantos docs diferentes debe\n",
    "                                       # aparecer una palabra para ser \n",
    "                                       # considerada para el vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc5c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el vocabulario dados los datos\n",
    "matriz_representacion = cv.fit(df_rym)\n",
    "# Traducimos los datos la matriz de representacion\n",
    "df_rym_mr = matriz_representacion.transform(df_rym)\n",
    "# Mustramos\n",
    "df_rym_mr.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94214936",
   "metadata": {},
   "source": [
    "#### Minhash y distancia de Jaccard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99272a56",
   "metadata": {},
   "source": [
    "Para crear un modelo basado en Minhashing hacemos lo siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7718c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "minhash = MinHashLSH(inputCol      = 'features', \n",
    "                     outputCol     = 'hashes', \n",
    "                     numHashTables = 100)\n",
    "\n",
    "modelo_mh = minhash.fit(df_rym_mr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1a7a6b",
   "metadata": {},
   "source": [
    "Podemos mostrar como se ve la signature matrix creada a partir de la matriz de representacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f140a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rym_mh = modelo_mh.transform(df_rym_mr) \n",
    "\n",
    "df_rym_mh.limit(10) \\\n",
    "         .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34eeeb3",
   "metadata": {},
   "source": [
    "#### Similitud entre lineas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2a5ca9",
   "metadata": {},
   "source": [
    "Podemos calcular las distancias entre los elementos de dos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "similitud_entre_lineas = modelo_mh.approxSimilarityJoin(datasetA  = df_rym_mh,  \n",
    "                                                      datasetB  = df_rym_mh, \n",
    "                                                      threshold = 0.5, \n",
    "                                                      distCol   = 'dist_jaccard') \\\n",
    "                                    .select(col('datasetA.nombre').alias('nombre_1'), \n",
    "                                        col('datasetB.nombre').alias('nombre_2'), \n",
    "                                        col('dist_jaccard')) \\\n",
    "                                    .where(col('dist_jaccard') > 0) # Quitamos las que son iguales\n",
    "\n",
    "similitud_entre_lineas.show(4)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415b569d",
   "metadata": {},
   "source": [
    "Veamos cuantas si pudimos identificar los dialogos por personaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fff9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "coincidencias = similitud_entre_lineas.withColumn('coinciden', \n",
    "                                                    col('nombre_1') == col('nombre_2')) \\\n",
    "                                        .groupBy('coinciden') \\\n",
    "                                        .count() \\\n",
    "                                        .toPandas()\n",
    "\n",
    "sns.barplot( x    = 'coinciden', \n",
    "             y    = 'count', \n",
    "             data = coincidencias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ec9826",
   "metadata": {},
   "source": [
    "#### Vecinos mas cercanos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157cb61b",
   "metadata": {},
   "source": [
    "Calculamos los elementos mas cercanos a un elemento dado.\n",
    "\n",
    "Extraemos una linea correspondinete a Morty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c04b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "[renglon] = df_rym_mr.where(df_rym_mr.id == 170).collect()\n",
    "print(renglon)\n",
    "linea = renglon[3]\n",
    "print(linea)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c6a0c9",
   "metadata": {},
   "source": [
    "Buscamos los elementos mas cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa960e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecinos_cercanos = modelo_mh.approxNearestNeighbors(dataset             = df_rym_mh, \n",
    "                                                    key                 = linea, \n",
    "                                                    numNearestNeighbors = 50, \n",
    "                                                    distCol             = 'dist_jaccard') \\\n",
    "                            .where(col('dist_jaccard') > 0) # Quitamos la linea repetida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d335f6",
   "metadata": {},
   "source": [
    "Veamos cuantas lineas corresponden a cada personaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43bffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecinos_cercanos_hist = vecinos_cercanos.groupby('nombre') \\\n",
    "                                        .count() \\\n",
    "                                        .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778ab153",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot( x    = 'nombre', \n",
    "             y    = 'count', \n",
    "             data = vecinos_cercanos_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd94a34a",
   "metadata": {},
   "source": [
    "### Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d33734e",
   "metadata": {},
   "source": [
    "Haga alguna variacion del problema aqui presentado y explique sus resultados. Algunas de las cosas que podria hacer son:\n",
    "\n",
    "    Cambiar el conjutno de personajes considerados.\n",
    "    Cambiar al en el la limpieza de datos, no quitar stopwords, etc.\n",
    "    Cambrias los hiperparametros de los objetos CountVectorizer, MinHashLSH, etc.\n",
    "    Usar otra linea para los vecinos mas cercanos, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd564075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
